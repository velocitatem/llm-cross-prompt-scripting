# Injection Methods

This is a list of ways, in which an LLM might get injected with a malicious prompt or payload.

+ Social Media
 + Twitter
  + [Smart Feed](https://github.com/SmartLever/SmartFeeds),
+ Email [llm-security](https://github.com/greshake/llm-security)
+ Websites [llm-security](https://github.com/greshake/llm-security)
  + Bing
    + [splendidbing](https://github.com/velocitatem/llm-cross-prompt-scripting/blob/main/splendidbing.md)
    + [Indirect Prompt Injection on Bing Chat](https://greshake.github.io/)
